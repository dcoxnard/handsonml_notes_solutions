{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Traning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Why understand the math behind machine learnings models?* (Q)\n",
    "    - Quickly hone in on appropriate algorithms, or discard inappropriate ones\n",
    "    - Easily narrow down the search space of hyperparameters\n",
    "    - UNderstand debugging and model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Regression is a conceptually simple model that predicts by computing a weighted sum of the input features, plus offset\n",
    "    - $\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n $\n",
    "    - Or, more compactly, $\\hat{y} = h_\\theta(\\mathbf{x}) = \\pmb{\\theta} \\cdot \\pmb{x} = \\pmb{\\theta}^\\intercal \\pmb{x} $\n",
    "        - 1st feature in the $\\pmb{x}$ vector is always 1, to create the offset\n",
    "        - $h_\\theta(\\pmb{x})$ is the hypothesis function, which describes the target as a function of the features\n",
    "        - The value of $ \\pmb{\\theta} $ that minimizes the RMSE gives the model with best fit\n",
    "        - In practice, it is easier to minimize the MSE instead of the RMSE.  This gives the same reuslt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean Squared Error (MSE) is a measure of the average \"miss\" of the predictions from the ground truth:\n",
    "$$ MSE(\\pmb{X}, h_\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (\\pmb{\\theta}^\\intercal \\pmb{x}_i - y_i )^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Root Mean Squared Error (RMSE) is simply the square root of the MSE:\n",
    "$$ RMSE(\\pmb{X}, h_\\theta) = \\sqrt{MSE(\\pmb{X}, h_\\theta)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *In what situation would you train a machine learning model with a different loss function than the function used to evaluate model performance?* (Q)\n",
    "    - A different function might be easier/quicker to compute, such as using MSE instead of RMSE to fit a Linear Regression model\n",
    "    - A different function might be easier to differentiate\n",
    "    - In order to contrain the model, such as in a regularization setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The *Normal Equation* gives the closed-form solution to the optimization problem:\n",
    "$$ \\hat{\\pmb{\\theta}} = (\\pmb{X}^\\intercal \\pmb{X})^{-1} \\pmb{X}^\\intercal \\pmb{y} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFCgmcCKiQP0/Jo1XaBq9OIEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# An example\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)  # Normally distributed noise\n",
    "\n",
    "plt.scatter(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the solution using the normal equation.\n",
    "# This implementation calls out the fact that the solution\n",
    "# is achieved with a chain of matrix multiplications\n",
    "\n",
    "X_withbias = np.c_[np.ones(X.shape), X]\n",
    "theta_hat = np.linalg.inv(X_withbias.T.dot(X_withbias)).dot(X_withbias.T).dot(y)  # Normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.74376706],\n",
       "       [3.21209312]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# theta_hat is close to, but doens't precisely equal, the\n",
    "# values hardcoded in the cell above.\n",
    "theta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0], [2]])\n",
    "X_new_withbias = np.c_[np.ones(X_new.shape), X_new]\n",
    "y_pred = X_new_withbias.dot(theta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot(X_new, y_pred, color=\"red\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another example, this time using sklearn\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3.21209312]]), array([3.74376706]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, the learned parameters approximate, but don't equal,\n",
    "# the hardcoded values.\n",
    "lin_reg.coef_, lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.74376706],\n",
       "       [3.21209312]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, another example using numpy, which the sklearn\n",
    "# implementation is based on.\n",
    "theta_hat_svd, resid, rank, s = np.linalg.lstsq(X_withbias, y, rcond=1e-6)\n",
    "theta_hat_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The last example computes the Moore-Penrose (pseudo-)inverse of $\\pmb{X}$:\n",
    "    - $ \\hat{\\pmb{\\theta}} = \\pmb{X}^{+}\\pmb{y} $\n",
    "    - Can be computed directly with `np.linalg.pinv(X_withbias).dot(y)`\n",
    "    - Moorse-Penrose inverse is calculated using SVD\n",
    "        - $ \\pmb{U} \\pmb{\\Sigma} \\pmb{V}^\\intercal $\n",
    "        - `np.linalg.svd()`\n",
    "        - Computed by taking SVD of $\\pmb{X}$, set all small values in $\\pmb{\\Sigma}$ to zero, invert all its nonzero values, then transpose to get $ \\pmb{U} \\pmb{\\Sigma}^{+} \\pmb{V}^\\intercal $\n",
    "    - This is more efficient than copmuting the normal equation\n",
    "    - More robust to cases where $ \\pmb{X}^\\intercal \\pmb{X} $ cannot be inverted (i.e. it's singular)\n",
    "        - Such as $n_{cols} > n_{rows}$ or in multicollinearity setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Computational complexity of the Moore-Penrose approach is better than the Normal Equation approach\n",
    "    - Moore-Penrose approach used by `sklearn` is about $O(n^2)$\n",
    "    - Inversion of an $(n+1) \\times (n+1)$ matrix as in the normal equation is about $O(n^{2.4})$ to $O(n^3)$\n",
    "    - Efficiency of both approaches deteriorates in high dimensions\n",
    "    - Linear in the number of rows, so both approaches work well with large datasets\n",
    "    - Predictions are fast once model has been trained: linear w.r.t. both number of features and rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- In addition to the analytic method described above, a gradient descent-based method can be used\n",
    "- Gradient descent is a generic algorithm that can be used to find an optimum solution to many problems\n",
    "- The idea is to iteratively update model parameters in such a way that the loss is progressively minimized\n",
    "- Step size, i.e. learning rate, is an important parameter in the algorithm\n",
    "    - Too-large step size can cause the algorithm to diverge\n",
    "    - Too-small step size lengthens the time needed to converge\n",
    "    - In practice, learning rate is progressively decreased to better \"hone in\" on an optimum\n",
    "- Number of iterations must also be set well\n",
    "    - Too low and the algorithm won't yet have arrived at the optimum\n",
    "    - Too high is inefficient once the parameters stop changing\n",
    "- In practice, it is useful to \"early stop\" the algorithm once the gradient gets very small, i.e. has a norm below $ \\epsilon $, the tolerance\n",
    "    - When the loss is convex, the alrogithm takes $ O(\\frac{1}{\\epsilon}) $ time to reach the optimum.  Dividing $\\epsilon$ by 10 increases can increase the time by a factor of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient descent can't be guaranteed to find the global minimum in a complex loss landscape\n",
    "- However, if the loss function is convex, Gradient Descent will converge (given a not-too-large learning rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient descent benefits from features being scaled, otherwise it can take longer to converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To implement the Gradient Descent algorithmL\n",
    "    - Compute the gradient of the cost function w.r.t. each parameter $\\theta_j$\n",
    "        - In the linear regrerssion example, this is $$ \\frac{\\partial}{\\partial \\theta_j}MSE(\\pmb{\\theta}) = \\frac{2}{m}\\sum_{i=1}^{m} (\\pmb{\\theta}^\\intercal \\pmb{x}_i - y_i)x_{ij} $$\n",
    "        - This can be computed in one go: $$ \\nabla_{\\theta}MSE(\\pmb{\\theta}) = \\frac{2}{m}\\pmb{X}^\\intercal(\\pmb{X}\\pmb{\\theta} - \\pmb{y}) $$\n",
    "    - The gradient is a vector of partial derivatives, with length equal to the number of model parameters\n",
    "    - Note that this requires computing the gradient over the _entire_ training set at each step in teh descent.  This is not very efficient, so there are modifications to the algorithm that give a speedup\n",
    "    - Finally, compute the next step in terms of the previous step: $$ \\pmb{\\theta}_{next} = \\pmb{\\theta} = \\eta\\nabla_{\\theta}MSE(\\pmb{\\theta}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.92038851],\n",
       "       [2.86817861]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = 0.1\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "\n",
    "theta = np.random.randn(2, 1)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_withbias.T.dot(X_withbias.dot(theta) - y)\n",
    "    theta = theta - eta * gradients\n",
    "    \n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stochastic Gradient Descent balances the advantages and disadvantages of calculating the gradient on the entire training data set\n",
    "    - Computationally expensive to use entire training set, but contains the most information possible\n",
    "    - SGD performs the process on a single training instance per iteration, instead of the entire training set\n",
    "    - Result is a faster algorithm, the speed of which comes at the cost of less reliable gradient information\n",
    "    - As a result, model loss is more likely to \"bounce around\" before settling at the optimum\n",
    "    - Also, the alrgorithm will stop close to, but not on the optimum point\n",
    "    - In practice, slowly decreasing the learning rate helps prevent the algorithm from jumping off the optimum by too much\n",
    "    - Too-fast reduction may result in the algorithm being stuck in a local minimum\n",
    "    - Too-slow reduction may reuslt in ending up fairly far from the actual optimum point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy implementation\n",
    "\n",
    "n_epochs = 50\n",
    "t0, t1 = 5, 50\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "\n",
    "theta = np.random.randn(2, 1)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_withbias[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "        eta = learning_schedule(epoch * m * i)\n",
    "        theta = theta - eta * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.68542302],\n",
       "       [2.65210196]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "             eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
       "             n_iter_no_change=5, penalty=None, power_t=0.25, random_state=None,\n",
       "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn's SGDRegression defaults to using MSE cost function\n",
    "\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1)\n",
    "sgd_reg.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.95290683]), array([2.91362061]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left off at Minibatch Gradient Descent, pg 186"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homl",
   "language": "python",
   "name": "homl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
